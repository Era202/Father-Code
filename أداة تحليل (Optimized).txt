# ==============================================================================
# MRP BOM Analysis - Optimized single-file Streamlit app
# - Modularized (helper functions)
# - Keeps original behavior and outputs (Excel writer openpyxl)
# - Comments in Arabic for maintainability
# Developed by: Refactor based on original by Reda Roshdy
# ==============================================================================

import streamlit as st
import pandas as pd
from io import BytesIO

# -------------------------
# ----- Helper Functions ---
# -------------------------

def auto_detect(df, candidates):
    """
    Ø§Ø®ØªÙØ± Ø£ÙˆÙ„ Ø¹Ù…ÙˆØ¯ Ù…Ù† candidates Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ df.columns.
    Ù„Ùˆ ÙˆÙ„Ø§ ÙˆØ§Ø­Ø¯ Ù…ÙˆØ¬ÙˆØ¯ØŒ Ø§Ø±Ø¬Ø¹ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£ÙˆÙ„ ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙƒÙ€ fallback.
    """
    for col in candidates:
        if col in df.columns:
            return col
    return df.columns[0]

def try_get_col(df, candidates):
    """
    Ø­Ø§ÙˆÙ„ ØªØ¬ÙŠØ¨ Ø£ÙˆÙ„ Ø¹Ù…ÙˆØ¯ Ù…Ù† candidatesØŒ Ø£Ùˆ Ø§Ø±Ø¬Ø¹ None Ù„Ùˆ Ø§Ù„Ø¯Ø§ØªØ§ None Ø£Ùˆ Ù…ÙÙŠÙ‡ÙˆØ´.
    """
    if df is None:
        return None
    for c in candidates:
        if c in df.columns:
            return c
    return None

def read_sheets(file, bom_sheet, father_sheet, mrp_sheet):
    """
    Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø´ÙŠØªØ§Øª Ø§Ù„Ù…Ø®ØªØ§Ø±Ø© ÙˆØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©.
    """
    bom_df = pd.read_excel(file, sheet_name=bom_sheet)
    father_df = pd.read_excel(file, sheet_name=father_sheet) if father_sheet != "None" else None
    mrp_df = pd.read_excel(file, sheet_name=mrp_sheet) if mrp_sheet != "None" else None

    # ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ù† Ù…Ø³Ø§ÙØ§Øª
    bom_df.columns = [str(c).strip() for c in bom_df.columns]
    if father_df is not None:
        father_df.columns = [str(c).strip() for c in father_df.columns]
    if mrp_df is not None:
        mrp_df.columns = [str(c).strip() for c in mrp_df.columns]

    return bom_df, father_df, mrp_df

def build_bom_grouped(bom_df, code_col, component_col, qty_col=None):
    """
    Ø§Ø±Ø¬Ø¹ Ù‚Ø§Ù…ÙˆØ³: parent_code -> set(components) Ø£Ùˆ dict(component->qty) Ù„Ùˆ qty Ù…ÙˆØ¬ÙˆØ¯.
    """
    if qty_col:
        bom_grouped = bom_df.groupby(code_col).apply(
            lambda g: dict(zip(g[component_col], g[qty_col]))
        ).to_dict()
    else:
        bom_grouped = bom_df.groupby(code_col)[component_col].apply(set).to_dict()
    return bom_grouped

def build_mrp_dict(mrp_df, mrp_component_col):
    """
    Ø§Ø±Ø¬Ø¹ dict Ù„Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ MRP Control Ù„ØªØ³Ù‡ÙŠÙ„ Ø§Ù„lookup.
    """
    if mrp_df is None or mrp_component_col is None:
        return {}
    return mrp_df.drop_duplicates(subset=[mrp_component_col]).set_index(mrp_component_col).to_dict(orient='index')

def build_desc_lookup(bom_df, mrp_df, mrp_component_col, desc_col_bom, desc_col_mrp, component_col):
    """
    Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ù…ÙˆØ³ ÙˆØµÙ Ù„ÙƒÙ„ Ù…ÙƒÙˆÙ‘Ù† (ÙŠØ³ØªØ®Ø¯Ù… MRP Ø£ÙˆÙ„Ø§Ù‹ Ø«Ù… BOM Ù„ØªØ¹ÙˆÙŠØ¶ Ø§Ù„ÙØ¬ÙˆØ§Øª).
    """
    desc_lookup = {}
    if mrp_df is not None and mrp_component_col and desc_col_mrp:
        desc_lookup.update(
            mrp_df.dropna(subset=[mrp_component_col]).drop_duplicates(subset=[mrp_component_col])
            .set_index(mrp_component_col)[desc_col_mrp]
            .to_dict()
        )
    if desc_col_bom:
        bom_desc_map = (
            bom_df.dropna(subset=[component_col, desc_col_bom])
            .drop_duplicates(subset=[component_col])
            .set_index(component_col)[desc_col_bom]
            .to_dict()
        )
        for k, v in bom_desc_map.items():
            if k not in desc_lookup and pd.notna(v):
                desc_lookup[k] = v
    return desc_lookup

def reorder_columns_for_parent(df, children, ensure_component_first=False):
    """
    Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ Ø£Ø¹Ù…Ø¯Ø© parent_df ÙˆÙÙ‚ Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©:
    - first_block Ø«Ø§Ø¨Øª (Component Ø¥Ù† Ø·Ù„Ø¨Ù†Ø§)ØŒ
    - Ø«Ù… MRP_Controller, Order_Type Ù„Ùˆ Ù…ÙˆØ¬ÙˆØ¯ÙŠÙ†ØŒ
    - Ø«Ù… Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø¨Ù†Ø§Ø¡ØŒ
    - Ø«Ù… Ø£ÙŠ Ø£Ø¹Ù…Ø¯Ø© Ø¥Ø¶Ø§ÙÙŠØ©.
    if ensure_component_first=True Ø³ÙŠØ¶Ù…Ù† ÙˆØ¶Ø¹ 'Component' ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©.
    """
    if df is None or df.empty:
        return df
    child_columns = [str(c) for c in children]
    # ØªØ±ØªÙŠØ¨ Ø£Ø³Ø§Ø³ÙŠ Ù…ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø£ØµÙ„ÙŠ (Ù…Ø¹ Ø¥ØªØ§Ø­Ø© Component ÙÙŠ Ø§Ù„Ø£ÙˆÙ„ Ø¥Ø°Ø§ Ù…Ø·Ù„ÙˆØ¨)
    first_block = [
        "Component" if ensure_component_first else "Planning Material",
        "Component Description",
        "Total_Children",
        "Num_Children_with_Component",
        "Usage_%",
        "Deviation",
        "parent",
    ]
    # Ù„Ùˆ Ø·Ù„Ø¨Ù†Ø§ Ø¥Ø¬Ø¨Ø§Ø± Component Ø£ÙˆÙ„Ù‹Ø§ ÙˆÙˆØ¬Ø¯ØªÙ‡ØŒ Ù†Ø¶Ø¹Ù‡ ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
    if ensure_component_first:
        # Ù†ÙØ¶Ù„ "Component" Ø£ÙˆÙ„Ù‹Ø§ Ø«Ù… Ø¥Ø²Ø§Ù„Ø© Ø¶Ø¹Ù Ø§Ø­ØªÙ…Ø§Ù„ÙŠ ÙÙŠ first_block
        first_block = ["Component", "Component Description", "Total_Children",
                       "Num_Children_with_Component", "Usage_%", "Deviation", "parent"]
    rest_cols = [c for c in ["MRP_Controller", "Order_Type"] if c in df.columns] + child_columns
    others = [c for c in df.columns if c not in first_block + rest_cols]
    ordered = [c for c in first_block if c in df.columns] + rest_cols + others
    return df.reindex(columns=ordered)

def safe_to_int_display(df, int_cols):
    """
    ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙÙŠ int_cols ØªØ¹Ø±Ø¶ ÙƒØ£Ø¹Ø¯Ø§Ø¯ ØµØ­ÙŠØ­Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø·Ø¨Ø§Ø¹Ø© (Ù†Ø­ÙˆÙ‘Ù„ Ø§Ù„Ù‚ÙŠÙ… Ø¯Ø§Ø®Ù„ÙŠÙ‹Ø§).
    Ù„Ø§ ÙŠØ¹Ø¯Ù‘Ù„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙÙŠ Ø§Ù„Ø³ØªÙŠØª (Ù†Ø¹Ù…Ù„ Ù†Ø³Ø®Ø© Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¹Ø±Ø¶).
    """
    df_copy = df.copy()
    for col in int_cols:
        if col in df_copy.columns:
            # fillna then convert to numeric int if possible
            df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce').fillna(0).astype(int)
    return df_copy

def add_summary_row(summary_df):
    """
    Ø¥Ø¶Ø§ÙØ© ØµÙ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ§Øª/Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª Ø¥Ù„Ù‰ summary_df (ØªØ¹ØªÙ…Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©).
    ØªØ¹ÙŠØ¯ DataFrame Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ ØµÙ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù…ÙØ¶Ø§Ù ÙˆØ¥Ù†Ø¯ÙƒØ³ Ù…ÙØ¹Ø§Ø¯ ØªØ±ØªÙŠØ¨Ù‡.
    """
    if summary_df is None or summary_df.empty:
        return summary_df
    df = summary_df.copy()
    numeric_cols = df.select_dtypes(include='number').columns.tolist()
    # Ø§Ø¹ØªØ¨Ø§Ø± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­ØªÙˆÙŠØ© Ø¹Ù„Ù‰ % Ø£Ùˆ 'ØªØ´Ø§Ø¨Ù‡' ÙƒØ£Ø¹Ù…Ø¯Ø© Ù†Ø³Ø¨ÙŠØ© Ù†Ø­ØªØ§Ø¬ Ù„Ù‡Ø§ Ù…ØªÙˆØ³Ø·
    percent_cols = [c for c in numeric_cols if "%" in c or "ØªØ´Ø§Ø¨Ù‡" in c or "Usage_" in c or c.endswith("_%")]
    totals = df[numeric_cols].sum()
    averages = df[percent_cols].mean() if percent_cols else pd.Series(dtype=float)
    # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ Ø¨Ø§Ù„Ù…ØªÙˆØ³Ø· Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†Ø³Ø¨ÙŠØ©
    for col in percent_cols:
        totals[col] = averages.get(col, totals.get(col, 0))
    totals_row = pd.DataFrame(totals).T
    totals_row["Parent_Code"] = "ğŸ”¢ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ§Øª / Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª"
    summary_with_totals = pd.concat([df, totals_row], ignore_index=True)
    # ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ù†Ø¯ÙƒØ³ ÙØ±ÙŠØ¯
    summary_with_totals = summary_with_totals.reset_index(drop=True)
    return summary_with_totals

def export_results_to_excel(output_buffer, per_parent_dfs, summary_df, top10_global):
    """
    ÙƒØªØ§Ø¨Ø© Ø¬Ù…ÙŠØ¹ Ø´ÙŠØªØ§Øª Ø§Ù„Ù€ Parents + Summary_Report Ø¯Ø§Ø®Ù„ BytesIO Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… openpyxl.
    per_parent_dfs: dict(parent_name -> DataFrame) Ø£Ùˆ list of tuples (name, df)
    summary_df: DataFrame
    top10_global: DataFrame
    ÙŠØ¹ÙŠØ¯ BytesIO (Ù…ÙÙ…Ø±Ù‘Ø± Ø¨Ù†ÙØ³ Ø§Ù„Ù…Ø±Ø¬Ø¹).
    """
    with pd.ExcelWriter(output_buffer, engine="openpyxl") as writer:
        # per_parent_dfs may be list of tuples
        if isinstance(per_parent_dfs, dict):
            items = per_parent_dfs.items()
        else:
            items = per_parent_dfs
        for name, df in items:
            try:
                df.to_excel(writer, sheet_name=str(name)[:31], index=False)
            except Exception:
                # ØªØ¬Ù†Ø¨ ÙØ´Ù„ Ø§Ù„ÙƒØªØ§Ø¨Ø© Ù„Ø§Ø³Ù… Ø´ÙŠØª ØºÙŠØ± ØµØ§Ù„Ø­
                df.to_excel(writer, sheet_name=str(name)[:31], index=False)
        # Summary sheet
        if summary_df is not None:
            summary_df.to_excel(writer, sheet_name="Summary_Report", index=False)
        # Top10 sheet
        if top10_global is not None and not top10_global.empty:
            top10_global.to_excel(writer, sheet_name="Top10_Global", index=False)
    return output_buffer

# -------------------------
# ----- Streamlit UI ------
# -------------------------

st.set_page_config(page_title="MRP BOM Analysis", layout="wide")
st.subheader("ğŸš€ Ø§Ù„Ø£Ø¨Ù†Ø§Ø¡ Ù…Ø¹ Ø§Ù„Ø§Ø¨Ø§Ø¡ BOM Ø£Ø¯Ø§Ø© ØªØ­Ù„ÙŠÙ„ (Optimized)")
st.markdown("---")

# Session state initialization (ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø£ØµÙ„ÙŠ)
if 'analysis_complete' not in st.session_state:
    st.session_state.analysis_complete = False
    st.session_state.summary_df = pd.DataFrame()
    st.session_state.top10_global = pd.DataFrame()
    st.session_state.per_parent_topdev = {}
    st.session_state.all_merged_df = pd.DataFrame()
    st.session_state.output_excel = BytesIO()

# Sidebar inputs (ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©)
st.sidebar.header("âš™ï¸ 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„")
uploaded_file = st.sidebar.file_uploader("â¬†ï¸ Ø§Ø±ÙØ¹ Ù…Ù„Ù Excel", type=["xlsx"])

if uploaded_file is None:
    st.info("ğŸ‘‹ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù Excel Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„.")
    st.stop()

try:
    xls = pd.ExcelFile(uploaded_file)
    sheets = xls.sheet_names

    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ“„ 2. Ø§Ø®ØªØ± Ø§Ù„Ø´ÙŠØªØ§Øª")

    default_bom = sheets.index("Bom") if "Bom" in sheets else 0
    bom_sheet = st.sidebar.selectbox("Ø§Ø®ØªØ± Ø´ÙŠØª Ø§Ù„Ù€ BOM", options=sheets, index=default_bom)

    father_options = ["None"] + sheets
    default_father = 1 + sheets.index("father code") if "father code" in sheets else 0
    father_sheet = st.sidebar.selectbox("Ø§Ø®ØªØ± Ø´ÙŠØª Ø§Ù„Ù€ Father", options=father_options, index=default_father)

    mrp_options = ["None"] + sheets
    default_mrp = 1 + sheets.index("MRP Contro") if "MRP Contro" in sheets else 0
    mrp_sheet = st.sidebar.selectbox("Ø§Ø®ØªØ± Ø´ÙŠØª MRP Contro (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", options=mrp_options, index=default_mrp)

    # Ù‚Ø±Ø§Ø¡Ø© ÙˆØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø´ÙŠØªØ§Øª
    bom_df, father_df, mrp_control_df = read_sheets(uploaded_file, bom_sheet, father_sheet, mrp_sheet)

    # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    code_col = auto_detect(bom_df, ['Code', 'Material', 'Parent', 'Planning Material'])
    component_col = auto_detect(bom_df, ['Component', 'Item', 'Material Name'])

    qty_col = None
    qty_candidates = [c for c in ['Qty', 'Quantity', 'Component Quantity', 'Quantity_Per'] if c in bom_df.columns]
    if qty_candidates:
        qty_col = auto_detect(bom_df, qty_candidates)

    parent_col, child_col = None, None
    if father_df is not None:
        parent_col = auto_detect(father_df, ['Parent', 'Planning Material', 'Parent_Material'])
        child_col = auto_detect(father_df, ['Material', 'Child', 'Child_Material'])

    # MRP columns detection
    mrp_component_col = None
    mrp_controller_col = None
    mrp_order_type_col = None
    if mrp_control_df is not None:
        mrp_component_col = auto_detect(mrp_control_df, ['Component', 'Material'])
        mrp_controller_col = try_get_col(mrp_control_df, [
            'MRP_Controller', 'MRP Controller', 'MRP controller', 'MRPC', 'MFC'
        ]) or auto_detect(mrp_control_df, ['MRP_Controller', 'MFC'])
        mrp_order_type_col = try_get_col(mrp_control_df, [
            'Order_Type', 'Order Type', 'Order type', 'Type'
        ]) or auto_detect(mrp_control_df, ['Order_Type', 'Type'])

    # description candidates
    desc_candidates = [
        'Component Description', 'Component_Description',
        'Description', 'Material Description', 'Short Text',
        'Item Description', 'Component Name', 'Material Name', 'Name'
    ]
    desc_col_bom = try_get_col(bom_df, desc_candidates)
    desc_col_mrp = try_get_col(mrp_control_df, desc_candidates) if mrp_control_df is not None else None

    # parents available and selection
    parents_available = sorted(father_df[parent_col].dropna().unique().astype(str)) if father_df is not None else []
    selected_parents = st.sidebar.multiselect("Ø§Ø®ØªØ± Parent(s) Ù„Ù„ØªØ­Ù„ÙŠÙ„", options=parents_available, default=parents_available)

    # filters for Order Type and MRP Controller
    selected_order_types = []
    selected_mrp_controllers = []
    if mrp_control_df is not None and mrp_order_type_col in mrp_control_df.columns:
        order_types_options = sorted(mrp_control_df[mrp_order_type_col].dropna().astype(str).unique().tolist())
        selected_order_types = st.sidebar.multiselect(
            "ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ Order Type (Ù…ØªØ¹Ø¯Ø¯)",
            options=order_types_options,
            default=order_types_options,
            help="Ø§ØªØ±ÙƒÙ‡Ø§ ÙƒÙ…Ø§ Ù‡ÙŠ Ù„Ø¹Ø¯Ù… ØªØ¶ÙŠÙŠÙ‚ Ø§Ù„Ù†ØªØ§Ø¦Ø¬Ø› Ø§Ø®ØªØ± Ù‚ÙŠÙ…Ù‹Ø§ Ù…Ø­Ø¯Ø¯Ø© Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„ØªØ±."
        )
    if mrp_control_df is not None and mrp_controller_col in mrp_control_df.columns:
        mrp_ctrl_options = sorted(mrp_control_df[mrp_controller_col].dropna().astype(str).unique().tolist())
        selected_mrp_controllers = st.sidebar.multiselect(
            "ÙÙ„ØªØ±Ø© Ø­Ø³Ø¨ MRP Controller (Ù…ØªØ¹Ø¯Ø¯)",
            options=mrp_ctrl_options,
            default=mrp_ctrl_options,
            help="Ø§ØªØ±ÙƒÙ‡Ø§ ÙƒÙ…Ø§ Ù‡ÙŠ Ù„Ø¹Ø¯Ù… ØªØ¶ÙŠÙŠÙ‚ Ø§Ù„Ù†ØªØ§Ø¦Ø¬Ø› Ø§Ø®ØªØ± Ù‚ÙŠÙ…Ù‹Ø§ Ù…Ø­Ø¯Ø¯Ø© Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„ØªØ±."
        )

    # ------------------------
    # Ø²Ø± ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„
    # ------------------------
    st.sidebar.markdown("---")
    if st.sidebar.button("ğŸš€ ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„", type="primary"):
        with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."):
            # ØªÙ†Ø¸ÙŠÙ ÙˆØªØ­ÙˆÙŠÙ„ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ù†Øµ ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            bom_df[code_col] = bom_df[code_col].astype(str).str.strip()
            bom_df[component_col] = bom_df[component_col].astype(str).str.strip()
            if father_df is not None:
                father_df[parent_col] = father_df[parent_col].astype(str).str.strip()
                father_df[child_col] = father_df[child_col].astype(str).str.strip()
            if mrp_control_df is not None and mrp_component_col:
                mrp_control_df[mrp_component_col] = mrp_control_df[mrp_component_col].astype(str).str.strip()

            # ØªØ¬Ù…ÙŠØ¹ BOM ÙˆMRP Ùˆdesc_lookup
            bom_grouped = build_bom_grouped(bom_df, code_col, component_col, qty_col)
            mrp_dict = build_mrp_dict(mrp_control_df, mrp_component_col)
            desc_lookup = build_desc_lookup(bom_df, mrp_control_df, mrp_component_col, desc_col_bom, desc_col_mrp, component_col)

            # ØªÙ‡ÙŠØ¦Ø© Ù‚ÙˆØ§Ø¦Ù… Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            summary_list = []
            per_parent_topdev = {}
            all_parents_rows = []

            # Ù†ÙƒØªØ¨ ÙƒÙ„ Parent ÙÙŠ Ø´ÙŠØª Ø®Ø§Øµ Ø¯Ø§Ø®Ù„ Ù…Ù„Ù Ø§Ù„Ø¥ÙƒØ³Ù„ (Ù†Ø¬Ù‡Ø² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹)
            output = BytesIO()
            # Ù†Ø³ØªØ®Ø¯Ù… Ù‚Ø§Ø¦Ù…Ø© Ù…Ø¤Ù‚ØªØ© Ù„Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø£Ø³Ù…Ø§Ø¡ ÙˆDFs Ù„ÙƒÙ„ parent Ù„Ù„ÙƒØªØ§Ø¨Ø© Ù„Ø§Ø­Ù‚Ù‹Ø§
            parent_sheets = []

            for parent in selected_parents:
                parent = str(parent).strip()
                children = father_df[father_df[parent_col] == parent][child_col].dropna().astype(str).unique().tolist() if father_df is not None else []
                total_children = len(children)
                parent_components = bom_grouped.get(parent, set())

                # Ù†ÙƒÙˆÙ‘Ù† ØµÙÙˆÙ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù„ÙƒÙ„ component
                usage_rows = []
                for comp in parent_components:
                    mrp_info = mrp_dict.get(comp, {})

                    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„Ø§ØªØ± Ø¥Ù† ÙˆÙØ¬Ø¯Øª
                    if selected_order_types:
                        if str(mrp_info.get(mrp_order_type_col)) not in set(selected_order_types):
                            continue
                    if selected_mrp_controllers:
                        if str(mrp_info.get(mrp_controller_col)) not in set(selected_mrp_controllers):
                            continue

                    count = 0
                    child_usage = {}
                    for child in children:
                        child_components = bom_grouped.get(child, {})
                        if qty_col and isinstance(child_components, dict):
                            qty_value = child_components.get(comp, 0)
                        else:
                            qty_value = 1 if comp in child_components else 0
                        child_usage[child] = qty_value
                        if qty_value > 0:
                            count += 1

                    usage_pct = round(count / total_children * 100, 2) if total_children > 0 else 0.0
                    row = {
                        component_col: comp,
                        "Component Description": desc_lookup.get(comp, ""),
                        "Total_Children": total_children,
                        "Num_Children_with_Component": count,
                        "Usage_%": usage_pct,
                        "MRP_Controller": mrp_info.get(mrp_controller_col),
                        "Order_Type": mrp_info.get(mrp_order_type_col)
                    }
                    row.update(child_usage)
                    usage_rows.append(row)

                # Ø¥Ù†Ø´Ø§Ø¡ DataFrame Ù„Ù„Ù€ parent ÙˆØ§Ø­ØªØ³Ø§Ø¨ Deviation ÙˆØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
                parent_df = pd.DataFrame(usage_rows)
                if not parent_df.empty:
                    # ØªÙˆØ­ÙŠØ¯ Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø¥Ù„Ù‰ 'Component'
                    if component_col != 'Component' and component_col in parent_df.columns:
                        parent_df.rename(columns={component_col: 'Component'}, inplace=True)

                    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù
                    parent_df["Deviation"] = abs(parent_df["Num_Children_with_Component"] - (total_children))

                    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: Ù†Ø¶Ù…Ù† ÙˆØ¬ÙˆØ¯ Component Ø£ÙˆÙ„Ø§Ù‹ ÙƒÙ…Ø§ Ø·Ù„Ø¨Øª Ø³Ø§Ø¨Ù‚Ø§Ù‹
                    parent_df = reorder_columns_for_parent(parent_df, children, ensure_component_first=True)

                    # Ø¥Ø¶Ø§ÙØ© Ù„Ù„ÙƒØªØ§Ø¨Ø© ÙÙŠ Ø§Ù„Ø¥ÙƒØ³Ù„ Ù„Ø§Ø­Ù‚Ù‹Ø§
                    parent_sheets.append((parent, parent_df.copy()))

                    # Ø£Ø¹Ù„Ù‰ Ø§Ù„Ø§Ù†Ø­Ø±Ø§ÙØ§Øª Ù„Ù‡Ø°Ø§ Parent
                    per_parent_topdev[parent] = parent_df.sort_values("Deviation", ascending=False).head(10)

                    # ØªØ¬Ù…ÙŠØ¹ Ù„Ù„ÙƒÙÙ„ (Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Top10 global)
                    all_parents_rows.append(parent_df.assign(Parent=parent))

                # Ù…Ù„Ø®Ù‘Øµ Ù„Ù„Ù€ Parent (Ø³Ø·Ø± ÙˆØ§Ø­Ø¯)
                total_comps = int(len(parent_df)) if 'parent_df' in locals() and not parent_df.empty else 0
                shared_comps = int(parent_df['Num_Children_with_Component'].gt(0).sum()) if total_comps > 0 else 0
                similarity_pct = round(shared_comps / total_comps * 100, 2) if total_comps > 0 else 0.0
                summary_list.append({
                    "Parent_Code": parent,
                    "Num_Children": total_children,
                    "Total_Components": total_comps,
                    "Shared_Components": shared_comps,
                    "Shared_Components_%": similarity_pct
                })

            # Ø¨Ø¹Ø¯ Ø§Ù„Ù„ÙˆØ¨: Ø¨Ù†Ø§Ø¡ summary_df ÙˆØªÙˆÙ„ÙŠØ¯ Top10 Ùˆ all_merged_df
            st.session_state.summary_df = pd.DataFrame(summary_list)
            if all_parents_rows:
                all_merged_df = pd.concat(all_parents_rows, ignore_index=True)
                # ØªÙˆØ­ÙŠØ¯ Ø§Ø³Ù… Component Ù„Ùˆ ÙƒØ§Ù† Ù…Ø®ØªÙ„ÙÙ‹Ø§
                if component_col != 'Component' and component_col in all_merged_df.columns:
                    all_merged_df = all_merged_df.rename(columns={component_col: 'Component'})
                st.session_state.all_merged_df = all_merged_df
                st.session_state.top10_global = all_merged_df.sort_values("Deviation", ascending=False).head(10)
            st.session_state.per_parent_topdev = per_parent_topdev

            # ØªØ¬Ù‡ÙŠØ² Summary Ù…Ø¹ ØµÙ Ø§Ù„Ø§Ø¬Ù…Ø§Ù„ÙŠØ§Øª (Ù„Ù„ÙƒØ´Ù/Ø§Ù„Ø¹Ø±Ø¶ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø³ØªØ±ÙŠÙ…Ù„ÙŠØª)
            summary_with_totals = add_summary_row(st.session_state.summary_df)
            st.session_state.summary_display_df = summary_with_totals

            # ÙƒØªØ§Ø¨Ø© ÙƒÙ„ Ø§Ù„Ø´ÙŠØªØ§Øª ÙÙŠ Ø§Ù„Ù€ BytesIO (Ø§Ù„ØªØ±ØªÙŠØ¨ ÙÙŠ parent_sheets Ø¬Ø§Ù‡Ø²)
            # Ù†Ø¶ÙŠÙ Ø£ÙŠØ¶Ø§Ù‹ Ø´ÙŠØª Summary_Report Ù…Ù† Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© (Ø¨Ø¯ÙˆÙ† ØµÙ Ø§Ù„Ø§Ø¬Ù…Ø§Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø¶Ø§Ù Ù„Ù„Ø¹Ø±Ø¶ ÙÙ‚Ø·)
            output = export_results_to_excel(output, parent_sheets, st.session_state.summary_df, st.session_state.top10_global)
            st.session_state.output_excel = output
            st.session_state.analysis_complete = True
            st.success("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­! ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† ØªØµÙØ­ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø£Ùˆ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥ÙƒØ³Ù„.")

    # ---------------------------
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (UI)
    # ---------------------------
    if not st.session_state.analysis_complete:
        st.info("â„¹ï¸ Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± 'ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„' Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬.")
    else:
        st.header("ğŸ“ˆ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„")

        col1, col2, col3 = st.columns(3)
        col1.metric("ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ Ø¹Ø¯Ø¯ Ø§Ù„Ù€ Parents", len(st.session_state.summary_df))
        avg_similarity = st.session_state.summary_df['Shared_Components_%'].mean() if not st.session_state.summary_df.empty else 0
        col2.metric("ğŸ”„ Ù…ØªÙˆØ³Ø· Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡", f"{avg_similarity:.2f}%")
        total_shared = st.session_state.summary_df['Shared_Components'].sum() if not st.session_state.summary_df.empty else 0
        col3.metric("ğŸ”— Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©", f"{total_shared}")

        tab1, tab2, tab3 = st.tabs(["ğŸ“Š Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ", "ğŸ”¥ Ø£Ø¹Ù„Ù‰ Ø§Ù„Ø§Ù†Ø­Ø±Ø§ÙØ§Øª", "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ ØªÙØ§ØµÙŠÙ„ ÙƒÙ„ Parent"])

        with tab1:
            st.subheader("Ù…Ù„Ø®Øµ Ø£Ø¯Ø§Ø¡ ÙƒÙ„ Parent")
            summary_df = st.session_state.summary_display_df.copy() if 'summary_display_df' in st.session_state else st.session_state.summary_df.copy()
            if not summary_df.empty:
                # Ø¹Ø±Ø¶ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¹Ø¯Ø¯ÙŠØ© ÙƒØ£Ø¹Ø¯Ø§Ø¯ ØµØ­ÙŠØ­Ø© Ù„Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¥Ù† ÙˆÙØ¬Ø¯Øª
                int_cols = ["Num_Children", "Total_Components", "Shared_Components"]
                summary_df = safe_to_int_display(summary_df, int_cols)
                # Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù†Ø³Ø¨: Ù†Ø¬Ø¹Ù„ Ø§Ù„Ø¹Ø±Ø¶ Ø¨Ø¯ÙˆÙ† ÙƒØ³ÙˆØ± Ø²Ø§Ø¦Ø¯Ø© (Ø¹Ø±Ø¶ ÙÙ‚Ø· ÙƒØ±Ù‚Ù… ØµØ­ÙŠØ­ Ù…Ø¹ %)
                if "Shared_Components_%" in summary_df.columns and "Shared_Components_%" not in st.session_state.summary_df.columns:
                    pass  # Ø­Ø§Ù„Ø© Ø®Ø§ØµØ© (Ù„Ø§ ØªØ­ØªØ§Ø¬ Ø¹Ø§Ø¯Ø©)
                # Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ (Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ø¥Ù†Ø¯ÙƒØ³)
                st.dataframe(summary_df, hide_index=True)

            st.markdown("---")
            # Ù‚Ø³Ù… Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø£Ù‚Ù„ Ù…Ø´Ø§Ø±ÙƒØ©
            if not st.session_state.all_merged_df.empty:
                low_shared_df = st.session_state.all_merged_df[st.session_state.all_merged_df['Usage_%'] < 100].sort_values('Usage_%')
                st.subheader("ğŸ“‰ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø£Ù‚Ù„ Ù…Ø´Ø§Ø±ÙƒØ© Ø¹Ø¨Ø± ÙƒÙ„ Ø§Ù„Ù€ Parents")
                display_first = ['Parent', 'Component', 'Component Description', 'Parents', 'Total_Children', 'Num_Children_with_Component', 'Usage_%']
                cols = [c for c in display_first if c in low_shared_df.columns] + [c for c in low_shared_df.columns if c not in display_first]
                st.dataframe(low_shared_df[cols].head(200), hide_index=True)

        with tab2:
            st.subheader("Ø£Ø¹Ù„Ù‰ 10 Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù†Ø­Ø±Ø§ÙÙ‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ")
            top10 = st.session_state.top10_global.copy()
            if not top10.empty:
                display_first = ['Parent', 'Component', 'Component Description', 'Total_Children', 'Num_Children_with_Component', 'Usage_%']
                cols = [c for c in display_first if c in top10.columns] + [c for c in top10.columns if c not in display_first]
                st.dataframe(top10[cols], hide_index=True)
            else:
                st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø¹Ø±Ø¶ Ø£Ø¹Ù„Ù‰ Ø§Ù„Ø§Ù†Ø­Ø±Ø§ÙØ§Øª.")

        with tab3:
            st.subheader("Ø§Ø³ØªØ¹Ø±Ø§Ø¶ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ù„ÙƒÙ„ Parent")
            parents_with_dev = list(st.session_state.per_parent_topdev.keys())
            if parents_with_dev:
                chosen_parent = st.selectbox("Ø§Ø®ØªØ± Parent Ù„Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„Ù‡", options=parents_with_dev)
                dfp = st.session_state.per_parent_topdev.get(chosen_parent, pd.DataFrame()).copy()
                if not dfp.empty:
                    display_first = ['Parent', 'Component', 'Component Description', 'Parents', 'Total_Children', 'Num_Children_with_Component', 'Usage_%']
                    cols = [c for c in display_first if c in dfp.columns] + [c for c in dfp.columns if c not in display_first]
                    st.dataframe(dfp[cols], hide_index=True)
                else:
                    st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù†Ø­Ø±Ø§Ù Ù„Ù‡Ø°Ø§ Ø§Ù„Ù€ Parent.")
            else:
                st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù†Ø­Ø±Ø§Ù Ù„Ø¹Ø±Ø¶Ù‡Ø§.")

        st.markdown("---")
        st.download_button(
            label="ğŸ—‚ï¸  (Excel) ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙƒØ§Ù…Ù„  ğŸ”¥",
            data=st.session_state.output_excel.getvalue(),
            file_name="MRP_BOM_Report_Optimized.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )

except Exception as e:
    # Ø¹Ø±Ø¶ Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
    st.exception(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")

# ---------------------------
# Footer
# ---------------------------
st.markdown(
    """
    <p style="text-align:center; margin-top:30px;">
        âœ¨ ØªÙ… Ø§Ù„ØªÙ†ÙÙŠØ° Ø¨ÙˆØ§Ø³Ø·Ø© <b>Ù… / Ø±Ø¶Ø§ Ø±Ø´Ø¯ÙŠ</b> â€“ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ‚ Ù…Ø­ÙÙˆØ¸Ø© Â© 2025 âœ¨
    </p>
    """,
    unsafe_allow_html=True
)
